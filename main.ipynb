{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torchsummary import summary\n",
    "from deepspeed.profiling.flops_profiler import get_model_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parameters = sum(p.numel() for p in models.resnet18().parameters())\n",
    "num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------- DeepSpeed Flops Profiler --------------------------\n",
      "Profile Summary at step 3:\n",
      "Notations:\n",
      "data parallel size (dp_size), model parallel size(mp_size),\n",
      "number of parameters (params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (flops), floating-point operations per second (FLOPS),\n",
      "fwd latency (forward propagation latency), bwd latency (backward propagation latency),\n",
      "step (weights update latency), iter latency (sum of fwd, bwd and step latency)\n",
      "\n",
      "params per gpu:                                               138.36 M\n",
      "params of model = params per GPU * mp_size:                   1       \n",
      "fwd MACs per GPU:                                             15.47 GMACs\n",
      "fwd flops per GPU:                                            30.97 G \n",
      "fwd flops of model = fwd flops per GPU * mp_size:             1       \n",
      "fwd latency:                                                  59.17 ms\n",
      "fwd FLOPS per GPU = fwd flops per GPU / fwd latency:          523.47 GFLOPS\n",
      "\n",
      "----------------------------- Aggregated Profile per GPU -----------------------------\n",
      "Top 3 modules in terms of params, MACs or fwd latency at different model depths:\n",
      "depth 0:\n",
      "    params      - {'VGG': '138.36 M'}\n",
      "    MACs        - {'VGG': '15.47 GMACs'}\n",
      "    fwd latency - {'VGG': '59.17 ms'}\n",
      "depth 1:\n",
      "    params      - {'Sequential': '138.36 M', 'AdaptiveAvgPool2d': '0'}\n",
      "    MACs        - {'Sequential': '15.47 GMACs', 'AdaptiveAvgPool2d': '0 MACs'}\n",
      "    fwd latency - {'Sequential': '58.98 ms', 'AdaptiveAvgPool2d': '88.21 us'}\n",
      "\n",
      "------------------------------ Detailed Profile per GPU ------------------------------\n",
      "Each module profile is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.\n",
      "\n",
      "VGG(\n",
      "  138.36 M, 100.00% Params, 15.47 GMACs, 100.00% MACs, 59.17 ms, 100.00% latency, 523.47 GFLOPS, \n",
      "  (features): Sequential(\n",
      "    14.71 M, 10.64% Params, 15.35 GMACs, 99.20% MACs, 34.01 ms, 57.48% latency, 903.35 GFLOPS, \n",
      "    (0): Conv2d(1.79 k, 0.00% Params, 86.7 MMACs, 0.56% MACs, 1.54 ms, 2.61% latency, 114.44 GFLOPS, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 420.57 us, 0.71% latency, 7.64 GFLOPS, inplace=True)\n",
      "    (2): Conv2d(36.93 k, 0.03% Params, 1.85 GMACs, 11.96% MACs, 3.26 ms, 5.52% latency, 1.13 TFLOPS, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 271.32 us, 0.46% latency, 11.84 GFLOPS, inplace=True)\n",
      "    (4): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 544.07 us, 0.92% latency, 5.9 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(73.86 k, 0.05% Params, 924.84 MMACs, 5.98% MACs, 1.3 ms, 2.20% latency, 1.42 TFLOPS, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 125.65 us, 0.21% latency, 12.78 GFLOPS, inplace=True)\n",
      "    (7): Conv2d(147.58 k, 0.11% Params, 1.85 GMACs, 11.96% MACs, 7.08 ms, 11.96% latency, 523.08 GFLOPS, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 125.17 us, 0.21% latency, 12.83 GFLOPS, inplace=True)\n",
      "    (9): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 799.89 us, 1.35% latency, 2.01 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(295.17 k, 0.21% Params, 924.84 MMACs, 5.98% MACs, 2.15 ms, 3.63% latency, 860.48 GFLOPS, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 106.57 us, 0.18% latency, 7.53 GFLOPS, inplace=True)\n",
      "    (12): Conv2d(590.08 k, 0.43% Params, 1.85 GMACs, 11.96% MACs, 2.24 ms, 3.79% latency, 1.65 TFLOPS, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 105.86 us, 0.18% latency, 7.58 GFLOPS, inplace=True)\n",
      "    (14): Conv2d(590.08 k, 0.43% Params, 1.85 GMACs, 11.96% MACs, 2.27 ms, 3.84% latency, 1.63 TFLOPS, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 103.71 us, 0.18% latency, 7.74 GFLOPS, inplace=True)\n",
      "    (16): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 164.75 us, 0.28% latency, 4.87 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(1.18 M, 0.85% Params, 924.84 MMACs, 5.98% MACs, 1.28 ms, 2.16% latency, 1.45 TFLOPS, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 79.39 us, 0.13% latency, 5.06 GFLOPS, inplace=True)\n",
      "    (19): Conv2d(2.36 M, 1.71% Params, 1.85 GMACs, 11.96% MACs, 2.51 ms, 4.24% latency, 1.48 TFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 75.1 us, 0.13% latency, 5.34 GFLOPS, inplace=True)\n",
      "    (21): Conv2d(2.36 M, 1.71% Params, 1.85 GMACs, 11.96% MACs, 2.06 ms, 3.48% latency, 1.79 TFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 76.29 us, 0.13% latency, 5.26 GFLOPS, inplace=True)\n",
      "    (23): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 172.14 us, 0.29% latency, 2.33 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(2.36 M, 1.71% Params, 462.42 MMACs, 2.99% MACs, 1.2 ms, 2.03% latency, 768.52 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 64.61 us, 0.11% latency, 1.55 GFLOPS, inplace=True)\n",
      "    (26): Conv2d(2.36 M, 1.71% Params, 462.42 MMACs, 2.99% MACs, 1.38 ms, 2.33% latency, 670.03 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 59.6 us, 0.10% latency, 1.68 GFLOPS, inplace=True)\n",
      "    (28): Conv2d(2.36 M, 1.71% Params, 462.42 MMACs, 2.99% MACs, 1.75 ms, 2.96% latency, 528.9 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 61.99 us, 0.10% latency, 1.62 GFLOPS, inplace=True)\n",
      "    (30): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 228.88 us, 0.39% latency, 438.44 MFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 88.21 us, 0.15% latency, 284.4 MFLOPS, output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    123.64 M, 89.36% Params, 123.63 MMACs, 0.80% MACs, 24.97 ms, 42.19% latency, 9.9 GFLOPS, \n",
      "    (0): Linear(102.76 M, 74.27% Params, 102.76 MMACs, 0.66% MACs, 19.86 ms, 33.56% latency, 10.35 GFLOPS, in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 86.07 us, 0.15% latency, 47.59 MFLOPS, inplace=True)\n",
      "    (2): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.21 us, 0.08% latency, 0.0 FLOPS, p=0.5, inplace=False)\n",
      "    (3): Linear(16.78 M, 12.13% Params, 16.78 MMACs, 0.11% MACs, 3.64 ms, 6.15% latency, 9.23 GFLOPS, in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 82.25 us, 0.14% latency, 49.8 MFLOPS, inplace=True)\n",
      "    (5): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 42.68 us, 0.07% latency, 0.0 FLOPS, p=0.5, inplace=False)\n",
      "    (6): Linear(4.1 M, 2.96% Params, 4.1 MMACs, 0.03% MACs, 1.01 ms, 1.71% latency, 8.11 GFLOPS, in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "------------------------------------------------------------------------------\n",
      "Batch size:                     1       \n",
      "Number of MACs:                 15.47 GMACs\n",
      "Number of parameters:           138.36 M\n",
      "Number of FLOPs:                30.97 G \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    model = models.vgg16()\n",
    "    batch_size = 1\n",
    "    flops, macs, params = get_model_profile(model=model, # model\n",
    "                                     input_shape=(batch_size, 3, 224, 224), # input shape or input to the input_constructor\n",
    "                                     print_profile=True, # prints the model graph with the measured profile attached to each module\n",
    "                                     top_modules=3, # the number of top modules to print aggregated profile\n",
    "                                     warm_up=3, # the number of warm-ups before measuring the time of each module\n",
    "    )\n",
    "    print(\"{:<30}  {:<8}\".format(\"Batch size: \", batch_size))\n",
    "    print('{:<30}  {:<8}'.format('Number of MACs: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    print('{:<30}  {:<8}'.format('Number of FLOPs: ', flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>op</th>\n",
       "      <th>nchannels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">conv</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(conv, 0), (conv, 1), (conv, 2), (conv, 3), (conv, 4), (conv, 5), (conv, 6), (conv, 7), (conv, 8)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.expand_frame_repr = False\n",
    "\n",
    "df = pd.read_csv(\"bench/results/20220511-011500/result.csv\", sep=\"\\t\")\n",
    "df.pivot_table(index=[\"op\", \"nchannels\"], columns=\"nthreads\", values=[\"comm_time\", \"comp_time\"], aggfunc=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nthreads</th>\n",
       "      <th>0</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>op</th>\n",
       "      <th>nchannels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">nop</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.8585</td>\n",
       "      <td>16.6105</td>\n",
       "      <td>9.1990</td>\n",
       "      <td>7.3385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6755</td>\n",
       "      <td>9.1275</td>\n",
       "      <td>4.9775</td>\n",
       "      <td>3.9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.5915</td>\n",
       "      <td>6.2380</td>\n",
       "      <td>3.7210</td>\n",
       "      <td>3.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.6895</td>\n",
       "      <td>4.8350</td>\n",
       "      <td>3.1390</td>\n",
       "      <td>2.7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.4815</td>\n",
       "      <td>4.0735</td>\n",
       "      <td>2.8845</td>\n",
       "      <td>2.6580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.6605</td>\n",
       "      <td>3.6675</td>\n",
       "      <td>2.7785</td>\n",
       "      <td>2.6665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1445</td>\n",
       "      <td>3.2525</td>\n",
       "      <td>2.8095</td>\n",
       "      <td>2.6015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7545</td>\n",
       "      <td>3.0675</td>\n",
       "      <td>2.7585</td>\n",
       "      <td>2.5390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "nthreads       0        64       128     256     512\n",
       "op  nchannels                                       \n",
       "nop 0          0.0      NaN      NaN     NaN     NaN\n",
       "    1          NaN  23.8585  16.6105  9.1990  7.3385\n",
       "    2          NaN  12.6755   9.1275  4.9775  3.9605\n",
       "    3          NaN   8.5915   6.2380  3.7210  3.0330\n",
       "    4          NaN   6.6895   4.8350  3.1390  2.7975\n",
       "    5          NaN   5.4815   4.0735  2.8845  2.6580\n",
       "    6          NaN   4.6605   3.6675  2.7785  2.6665\n",
       "    7          NaN   4.1445   3.2525  2.8095  2.6015\n",
       "    8          NaN   3.7545   3.0675  2.7585  2.5390"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "421a6ff2b1a4b930bf864cb3fe283f2faf75cdf9bc227d5af01813022d6f9609"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
