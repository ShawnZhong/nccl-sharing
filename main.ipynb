{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.profiler import profile, ProfilerActivity\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torchsummary import summary\n",
    "from deepspeed.profiling.flops_profiler import get_model_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11689512"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_parameters = sum(p.numel() for p in models.resnet18().parameters())\n",
    "num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------- DeepSpeed Flops Profiler --------------------------\n",
      "Profile Summary at step 3:\n",
      "Notations:\n",
      "data parallel size (dp_size), model parallel size(mp_size),\n",
      "number of parameters (params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (flops), floating-point operations per second (FLOPS),\n",
      "fwd latency (forward propagation latency), bwd latency (backward propagation latency),\n",
      "step (weights update latency), iter latency (sum of fwd, bwd and step latency)\n",
      "\n",
      "params per gpu:                                               138.36 M\n",
      "params of model = params per GPU * mp_size:                   1       \n",
      "fwd MACs per GPU:                                             15.47 GMACs\n",
      "fwd flops per GPU:                                            30.97 G \n",
      "fwd flops of model = fwd flops per GPU * mp_size:             1       \n",
      "fwd latency:                                                  59.17 ms\n",
      "fwd FLOPS per GPU = fwd flops per GPU / fwd latency:          523.47 GFLOPS\n",
      "\n",
      "----------------------------- Aggregated Profile per GPU -----------------------------\n",
      "Top 3 modules in terms of params, MACs or fwd latency at different model depths:\n",
      "depth 0:\n",
      "    params      - {'VGG': '138.36 M'}\n",
      "    MACs        - {'VGG': '15.47 GMACs'}\n",
      "    fwd latency - {'VGG': '59.17 ms'}\n",
      "depth 1:\n",
      "    params      - {'Sequential': '138.36 M', 'AdaptiveAvgPool2d': '0'}\n",
      "    MACs        - {'Sequential': '15.47 GMACs', 'AdaptiveAvgPool2d': '0 MACs'}\n",
      "    fwd latency - {'Sequential': '58.98 ms', 'AdaptiveAvgPool2d': '88.21 us'}\n",
      "\n",
      "------------------------------ Detailed Profile per GPU ------------------------------\n",
      "Each module profile is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, fwd latency, percentage of total fwd latency, fwd FLOPS\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). They are not counted as submodules, thus not to be printed out. However they make up the difference between a parent's MACs (or latency) and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "3. The fwd latency listed in the top module's profile is directly captured at the module forward function in PyTorch, thus it's less than the fwd latency shown above which is captured in DeepSpeed.\n",
      "\n",
      "VGG(\n",
      "  138.36 M, 100.00% Params, 15.47 GMACs, 100.00% MACs, 59.17 ms, 100.00% latency, 523.47 GFLOPS, \n",
      "  (features): Sequential(\n",
      "    14.71 M, 10.64% Params, 15.35 GMACs, 99.20% MACs, 34.01 ms, 57.48% latency, 903.35 GFLOPS, \n",
      "    (0): Conv2d(1.79 k, 0.00% Params, 86.7 MMACs, 0.56% MACs, 1.54 ms, 2.61% latency, 114.44 GFLOPS, 3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 420.57 us, 0.71% latency, 7.64 GFLOPS, inplace=True)\n",
      "    (2): Conv2d(36.93 k, 0.03% Params, 1.85 GMACs, 11.96% MACs, 3.26 ms, 5.52% latency, 1.13 TFLOPS, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 271.32 us, 0.46% latency, 11.84 GFLOPS, inplace=True)\n",
      "    (4): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 544.07 us, 0.92% latency, 5.9 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(73.86 k, 0.05% Params, 924.84 MMACs, 5.98% MACs, 1.3 ms, 2.20% latency, 1.42 TFLOPS, 64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 125.65 us, 0.21% latency, 12.78 GFLOPS, inplace=True)\n",
      "    (7): Conv2d(147.58 k, 0.11% Params, 1.85 GMACs, 11.96% MACs, 7.08 ms, 11.96% latency, 523.08 GFLOPS, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 125.17 us, 0.21% latency, 12.83 GFLOPS, inplace=True)\n",
      "    (9): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 799.89 us, 1.35% latency, 2.01 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(295.17 k, 0.21% Params, 924.84 MMACs, 5.98% MACs, 2.15 ms, 3.63% latency, 860.48 GFLOPS, 128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 106.57 us, 0.18% latency, 7.53 GFLOPS, inplace=True)\n",
      "    (12): Conv2d(590.08 k, 0.43% Params, 1.85 GMACs, 11.96% MACs, 2.24 ms, 3.79% latency, 1.65 TFLOPS, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 105.86 us, 0.18% latency, 7.58 GFLOPS, inplace=True)\n",
      "    (14): Conv2d(590.08 k, 0.43% Params, 1.85 GMACs, 11.96% MACs, 2.27 ms, 3.84% latency, 1.63 TFLOPS, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 103.71 us, 0.18% latency, 7.74 GFLOPS, inplace=True)\n",
      "    (16): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 164.75 us, 0.28% latency, 4.87 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(1.18 M, 0.85% Params, 924.84 MMACs, 5.98% MACs, 1.28 ms, 2.16% latency, 1.45 TFLOPS, 256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 79.39 us, 0.13% latency, 5.06 GFLOPS, inplace=True)\n",
      "    (19): Conv2d(2.36 M, 1.71% Params, 1.85 GMACs, 11.96% MACs, 2.51 ms, 4.24% latency, 1.48 TFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 75.1 us, 0.13% latency, 5.34 GFLOPS, inplace=True)\n",
      "    (21): Conv2d(2.36 M, 1.71% Params, 1.85 GMACs, 11.96% MACs, 2.06 ms, 3.48% latency, 1.79 TFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 76.29 us, 0.13% latency, 5.26 GFLOPS, inplace=True)\n",
      "    (23): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 172.14 us, 0.29% latency, 2.33 GFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(2.36 M, 1.71% Params, 462.42 MMACs, 2.99% MACs, 1.2 ms, 2.03% latency, 768.52 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 64.61 us, 0.11% latency, 1.55 GFLOPS, inplace=True)\n",
      "    (26): Conv2d(2.36 M, 1.71% Params, 462.42 MMACs, 2.99% MACs, 1.38 ms, 2.33% latency, 670.03 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 59.6 us, 0.10% latency, 1.68 GFLOPS, inplace=True)\n",
      "    (28): Conv2d(2.36 M, 1.71% Params, 462.42 MMACs, 2.99% MACs, 1.75 ms, 2.96% latency, 528.9 GFLOPS, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 61.99 us, 0.10% latency, 1.62 GFLOPS, inplace=True)\n",
      "    (30): MaxPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 228.88 us, 0.39% latency, 438.44 MFLOPS, kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0, 0.00% Params, 0 MACs, 0.00% MACs, 88.21 us, 0.15% latency, 284.4 MFLOPS, output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    123.64 M, 89.36% Params, 123.63 MMACs, 0.80% MACs, 24.97 ms, 42.19% latency, 9.9 GFLOPS, \n",
      "    (0): Linear(102.76 M, 74.27% Params, 102.76 MMACs, 0.66% MACs, 19.86 ms, 33.56% latency, 10.35 GFLOPS, in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 86.07 us, 0.15% latency, 47.59 MFLOPS, inplace=True)\n",
      "    (2): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 47.21 us, 0.08% latency, 0.0 FLOPS, p=0.5, inplace=False)\n",
      "    (3): Linear(16.78 M, 12.13% Params, 16.78 MMACs, 0.11% MACs, 3.64 ms, 6.15% latency, 9.23 GFLOPS, in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(0, 0.00% Params, 0 MACs, 0.00% MACs, 82.25 us, 0.14% latency, 49.8 MFLOPS, inplace=True)\n",
      "    (5): Dropout(0, 0.00% Params, 0 MACs, 0.00% MACs, 42.68 us, 0.07% latency, 0.0 FLOPS, p=0.5, inplace=False)\n",
      "    (6): Linear(4.1 M, 2.96% Params, 4.1 MMACs, 0.03% MACs, 1.01 ms, 1.71% latency, 8.11 GFLOPS, in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "------------------------------------------------------------------------------\n",
      "Batch size:                     1       \n",
      "Number of MACs:                 15.47 GMACs\n",
      "Number of parameters:           138.36 M\n",
      "Number of FLOPs:                30.97 G \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    model = models.vgg16()\n",
    "    batch_size = 1\n",
    "    flops, macs, params = get_model_profile(model=model, # model\n",
    "                                     input_shape=(batch_size, 3, 224, 224), # input shape or input to the input_constructor\n",
    "                                     print_profile=True, # prints the model graph with the measured profile attached to each module\n",
    "                                     top_modules=3, # the number of top modules to print aggregated profile\n",
    "                                     warm_up=3, # the number of warm-ups before measuring the time of each module\n",
    "    )\n",
    "    print(\"{:<30}  {:<8}\".format(\"Batch size: \", batch_size))\n",
    "    print('{:<30}  {:<8}'.format('Number of MACs: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    print('{:<30}  {:<8}'.format('Number of FLOPs: ', flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "421a6ff2b1a4b930bf864cb3fe283f2faf75cdf9bc227d5af01813022d6f9609"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
